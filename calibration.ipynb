{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ead7377-68ec-43a3-ba03-0eaee5104727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from os import path\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e071e506-404d-45b8-a8e2-cc809da3a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"labeled\"\n",
    "video_file = \"0.hevc\"\n",
    "text_file = \"0.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a630f4a-6e0e-4c55-9538-c5bd448c6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text file to array\n",
    "pitches, yaws = [], []\n",
    "with open(path.join(TRAIN_DIR, text_file), \"r\") as f:\n",
    "     for line in f:\n",
    "        pitch, yaw = line.split()\n",
    "        pitches.append(float(pitch))\n",
    "        yaws.append(float(yaw))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fe8c4-a382-42cf-ae6d-9cddfcf33f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86aebc5-ecf7-48b0-8201-4ca60efd584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(path.join(TRAIN_DIR, video_file))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d5a2aa-5dbf-4b5b-a4d7-2ca9097c22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Video params\n",
    "FPS = 20\n",
    "num_frames = 20*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1febe29-f33c-4b21-91fa-7bcb61eb7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(path.join(TRAIN_DIR, video_file))\n",
    "# ret, frame1 = cap.read()\n",
    "# prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "# hsv = np.zeros_like(frame1)\n",
    "# hsv[..., 1] = 255\n",
    "\n",
    "# magnitudes = []\n",
    "# angles = []\n",
    "\n",
    "# t = trange(num_frames)\n",
    "\n",
    "# for epoch in t:\n",
    "#     ret, frame2 = cap.read()\n",
    "#     if not ret:\n",
    "#         print('No frames grabbed!')\n",
    "#         break\n",
    "#     next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "#     flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "#     mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "#     magnitudes.append(mag.flatten())\n",
    "#     angles.append(ang.flatten())\n",
    "#     hsv[..., 0] = ang*180/np.pi/2\n",
    "#     hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
    "#     bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "#     # cv.imshow('frame2', bgr)\n",
    "#     # k = cv.waitKey(30) & 0xff\n",
    "#     # if k == 27:\n",
    "#     #     break\n",
    "#     # elif k == ord('s'):\n",
    "#     #     cv.imwrite('opticalfb.png', frame2)\n",
    "#     #     cv.imwrite('opticalhsv.png', bgr)\n",
    "#     prvs = next\n",
    "# # cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f06ee4-562c-459e-9e29-77d5b85a8240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save magnitude and angles\n",
    "\n",
    "import pickle\n",
    "# with open(\"magnitudes.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(magnitudes, f)\n",
    "\n",
    "    \n",
    "# with open(\"angles.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(angles, f)\n",
    "\n",
    "\n",
    "with open(\"magnitudes.pkl\", \"rb\") as f:\n",
    "    magnitudes = pickle.load(f)\n",
    "\n",
    "with open(\"angles.pkl\", \"rb\") as f:\n",
    "    angles = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fbfc9e-4476-4f7f-a790-96c8cad2782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_ang = []\n",
    "for i, el in enumerate(magnitudes):\n",
    "    mag_ang.append(np.concatenate((el, angles[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeed40c4-1692-46d0-8c1e-70a3484001a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mod_pitches = pitches[1:]\n",
    "mod_yaws = yaws[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a1e0ee6-75eb-4ef5-a606-bddbe6c02346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_mag_train, X_mag_test = train_test_split(magnitudes, test_size=0.2, random_state=25)\n",
    "X_ang_train, X_ang_test = train_test_split(angles, test_size=0.2, random_state=25)\n",
    "\n",
    "Y_pitch_train, Y_pitch_test = train_test_split(mod_pitches, test_size=0.2, random_state=25)\n",
    "Y_yaw_train, Y_yaw_test = train_test_split(mod_yaws, test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4dc388-8e58-481b-b3c9-c3b5038b337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.column_stack((X_mag_train, X_ang_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af7a84-09fc-4488-9671-52b90ffe9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "regr.fit(X_train, Y_pitch_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705bc22-f8b6-4533-9e53-3be5b5cdeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_test = np.column_stack(X_mag_test, X_ang_test)\n",
    "\n",
    "Y_pitch_pred = regr.predict(X_test)\n",
    "print(mean_squared_error(Y_pitch_test, Y_pitch_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ed571cc-98d2-44ac-9714-dbb87d676e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yaws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43myaws\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yaws' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# input dim is mag and ang flattened added together\n",
    "# (874 * 1164)*2\n",
    "\n",
    "# input_dim = (874 * 1164)*2\n",
    "\n",
    "# output_dim = 1\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "# class PitchNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Network, self).__init__()\n",
    "#         self.l1 = nn.Linear(input_dim, hidden_layers)\n",
    "#         self.act = nn.ReLU()\n",
    "#         self.l2 = nn.Linear(hidden_layers, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.l1(x)\n",
    "#         x = self.act(x)\n",
    "#         x = self.l2(x)\n",
    "#         return x\n",
    "\n",
    "# model = PitchNet()\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "\n",
    "# net = PitchNet()\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ddc44-1ce9-4593-826e-3f5c3547babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# BS = 32\n",
    "\n",
    "# t = trange(epochs)\n",
    "\n",
    "# losses, accuracies = [], []\n",
    "\n",
    "# for epoch in t:\n",
    "#     samp = np.random.randint(0, X_train.shape[0], size=(BS))\n",
    "\n",
    "#     X = torch.tensor(X_train[samp]).float()\n",
    "#     Y = torch.tensor(Y_train[samp]).long()\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     # forward propogation\n",
    "#     outputs = model(X)\n",
    "    \n",
    "#     cat = torch.argmax(outputs, dim=1)\n",
    "#     accuracy = (cat == Y).float().mean()\n",
    "    \n",
    "#     loss = loss_function(outputs, Y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     loss, accuracy = loss.item(), accuracy.item()\n",
    "#     losses.append(loss)\n",
    "#     accuracies.append(accuracy)\n",
    "    \n",
    "        \n",
    "#     t.set_description(f\"loss {loss:.2f} accuracy {accuracy:.2f}\")\n",
    "\n",
    "# print(f\"loss {loss:.2f} accuracy {accuracy:.2f}\")\n",
    "# plt.ylim(-1, 2)\n",
    "# plt.plot(losses, label=\"loss\")\n",
    "# plt.plot(accuracies, label=\"accuracy\")\n",
    "# plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
